# Exploring-Unlabelled-Speaker-Recognition

> **Refer to the full documentation (`Exploring Unlabelled Speaker Recognition Documentation.pdf`) if you need more detailed explanations.**

---

## 1 Overview

This repository proposes and outlines a **fully‚Äëunsupervised, high‚Äëaccuracy pipeline** for identifying *‚âà200* unique speakers in an unlabeled collection of WAV recordings.
The core idea:

1. **Pre‚Äëprocess** audio (resample, VAD, normalise).
2. **Embed** each utterance with a **pre‚Äëtrained ECAPA‚ÄëTDNN** (or x‚Äëvector) network.
3. **Cluster** the embedding vectors (HDBSCAN‚ÄØ/‚ÄØSpectral Clustering) to form speaker IDs.
4. **Validate** clusters using internal metrics & manual spot‚Äëchecks.

Most of the heavy lifting is done by the powerful speaker‚Äëembedding model, allowing accurate separation without labelled data.

---

## 2 Data Exploration & Analysis

| Step                                 | Purpose                               |
| ------------------------------------ | ------------------------------------- |
| Listen to samples                    | Gauge voice diversity & noise levels  |
| Waveform plots                       | Detect silence, clipping, long pauses |
| Spectrograms                         | Visualise pitch & formant patterns    |
| Basic statistics (pitch, MFCC means) | Spot broad clusters (e.g.¬†gender)     |

Challenges discovered:

* Varying recording quality & background noise.
* Possible near‚Äëidentical voices.
* No ground‚Äëtruth labels for evaluation.

---

## 3 Proposed Solution & Justification

| Component           | Choice                            | Rationale                                             |
| ------------------- | --------------------------------- | ----------------------------------------------------- |
| **Embeddings**      | ECAPA‚ÄëTDNN (192‚ÄëD)                | SOTA robustness; trained to separate speakers         |
| **Distance Metric** | Cosine                            | Invariant to loudness; aligns with embedding training |
| **Clustering**      | HDBSCAN ‚Äìor‚Äì Spectral             | Handles unequal cluster sizes; auto‚Äëdetects outliers  |
| **Evaluation**      | Silhouette, DBI, manual listening | Only viable when labels are absent                    |

Why it works: embeddings compress speaker identity into a compact vector; clustering then groups vectors that are naturally close in this space.

---

## 4 Conceptual Implementation Strategy

```text
preprocess.py
  - resample 16‚ÄØkHz mono
  - voice‚Äëactivity‚Äëdetect & trim
  - loudness normalise

extract_embeddings.py
  - load ECAPA model (SpeechBrain)
  - for each .wav ‚Üí 192‚ÄëD vector ‚Üí save to embeddings.npy

cluster_embeddings.py
  - load embeddings.npy
  - run HDBSCAN(min_cluster_size=2)
  - save cluster_labels.csv

evaluate.py
  - silhouette_score(embeddings, labels)
  - flag low‚Äësilhouette recordings for manual review
```

All code is **conceptual/pseudocode** and can be converted to runnable Python with minimal effort.

---

## 5 Challenges & Mitigations

| Challenge                 | Mitigation                                                                          |
| ------------------------- | ----------------------------------------------------------------------------------- |
| Similar‚Äësounding speakers | High‚Äëresolution ECAPA embeddings; iterative re‚Äëclustering of suspect large clusters |
| Noise / channel mismatch  | VAD + light spectral denoising; robustness of ECAPA (trained with augmentation)     |
| No ground truth           | Internal metrics; targeted manual listening; verification‚Äëscore cross‚Äëchecks        |
| Over‚Äë / under‚Äëclustering  | Compare HDBSCAN vs. fixed‚Äëk AHC, inspect cluster size distribution                  |


---

## 6 Repository Layout

```
/README.md              ‚Üê THIS FILE
/Exploring Unlabelled Speaker Recognition Documentation.pdf      ‚Üê Detailed write‚Äëup (all questions answered)
/code/
   preprocess.py*       ‚Üê audio cleaning (conceptual)
   extract_embeddings.py*
   cluster_embeddings.py*
   evaluate.py*
```

*(starred files are high‚Äëlevel pseudocode ‚Äì edit into real scripts as you iterate)*

---

## 7 Quick‚ÄëStart (Conceptual)

```bash
# 1. Prepare env
conda create -n speaker-dia python=3.10
conda activate speaker-dia
pip install speechbrain hdbscan librosa matplotlib

# 2. Run pipeline
python code/preprocess.py   # cleans /data/*.wav ‚Üí /data/clean/*.wav
python code/extract_embeddings.py  # ‚Üí embeddings.npy
python code/cluster_embeddings.py  # ‚Üí cluster_labels.csv
python code/evaluate.py     # prints silhouette & saves plots
```

---

## 8 Next Steps

1. Swap ECAPA for any newer embedding model if desired.
2. Iterate clustering parameters to hit exactly 200 clusters.
3. Build a small web dashboard to audition clusters and merge/split interactively.

---

*Project bootstrapped May 2025 ‚Äì innovation in progress üöß*
