# Exploring-Unlabelled-Speaker-Recognition

> **Refer to the full documentation (`Exploring Unlabelled Speaker Recognition Documentation.pdf`) if you need more detailed explanations.**

---

## 1â€¯ï¸âƒ£ Overview

This repository proposes and outlines a **fullyâ€‘unsupervised, highâ€‘accuracy pipeline** for identifying *â‰ˆ200* unique speakers in an unlabeled collection of WAV recordings.
The core idea:

1. **Preâ€‘process** audio (resample, VAD, normalise).
2. **Embed** each utterance with a **preâ€‘trained ECAPAâ€‘TDNN** (or xâ€‘vector) network.
3. **Cluster** the embedding vectors (HDBSCANâ€¯/â€¯Spectral Clustering) to form speaker IDs.
4. **Validate** clusters using internal metrics & manual spotâ€‘checks.

Most of the heavy lifting is done by the powerful speakerâ€‘embedding model, allowing accurate separation without labelled data.

---

## 2â€¯ï¸âƒ£ Data Exploration & Analysis

| Step                                 | Purpose                               |
| ------------------------------------ | ------------------------------------- |
| Listen to samples                    | Gauge voice diversity & noise levels  |
| Waveform plots                       | Detect silence, clipping, long pauses |
| Spectrograms                         | Visualise pitch & formant patterns    |
| Basic statistics (pitch, MFCC means) | Spot broad clusters (e.g.Â gender)     |

Challenges discovered:

* Varying recording quality & background noise.
* Possible nearâ€‘identical voices.
* No groundâ€‘truth labels for evaluation.

---

## 3â€¯ï¸âƒ£ Proposed Solution & Justification

| Component           | Choice                            | Rationale                                             |
| ------------------- | --------------------------------- | ----------------------------------------------------- |
| **Embeddings**      | ECAPAâ€‘TDNN (192â€‘D)                | SOTA robustness; trained to separate speakers         |
| **Distance Metric** | Cosine                            | Invariant to loudness; aligns with embedding training |
| **Clustering**      | HDBSCAN â€“orâ€“ Spectral             | Handles unequal cluster sizes; autoâ€‘detects outliers  |
| **Evaluation**      | Silhouette, DBI, manual listening | Only viable when labels are absent                    |

Why it works: embeddings compress speaker identity into a compact vector; clustering then groups vectors that are naturally close in this space.

---

## 4â€¯ï¸âƒ£ Conceptual Implementation Strategy

```text
preprocess.py
  - resample 16â€¯kHz mono
  - voiceâ€‘activityâ€‘detect & trim
  - loudness normalise

extract_embeddings.py
  - load ECAPA model (SpeechBrain)
  - for each .wav â†’ 192â€‘D vector â†’ save to embeddings.npy

cluster_embeddings.py
  - load embeddings.npy
  - run HDBSCAN(min_cluster_size=2)
  - save cluster_labels.csv

evaluate.py
  - silhouette_score(embeddings, labels)
  - flag lowâ€‘silhouette recordings for manual review
```

All code is **conceptual/pseudocode** and can be converted to runnable Python with minimal effort.

---

## 5â€¯ï¸âƒ£ Challenges & Mitigations

* **Similar voices** â†’ use ECAPA + fineâ€‘tune if clusters merge.
* **Background noise** â†’ VAD & optional spectral gating.
* **Uneven recordings per speaker** â†’ densityâ€‘aware clustering (HDBSCAN).
* **No labels** â†’ internal metrics & spotâ€‘check 5â€“10% clusters.

---

## 6â€¯ï¸âƒ£ Repository Layout

```
/README.md              â† THIS FILE
/docs/Proposal.pdf      â† Detailed writeâ€‘up (all questions answered)
/code/
   preprocess.py*       â† audio cleaning (conceptual)
   extract_embeddings.py*
   cluster_embeddings.py*
   evaluate.py*
```

*(starred files are highâ€‘level pseudocode â€“ edit into real scripts as you iterate)*

---

## 7â€¯ï¸âƒ£ Quickâ€‘Start (Conceptual)

```bash
# 1. Prepare env
conda create -n speaker-dia python=3.10
conda activate speaker-dia
pip install speechbrain hdbscan librosa matplotlib

# 2. Run pipeline
python code/preprocess.py   # cleans /data/*.wav â†’ /data/clean/*.wav
python code/extract_embeddings.py  # â†’ embeddings.npy
python code/cluster_embeddings.py  # â†’ cluster_labels.csv
python code/evaluate.py     # prints silhouette & saves plots
```

---

## 8â€¯ï¸âƒ£ Next Steps

1. Swap ECAPA for any newer embedding model if desired.
2. Iterate clustering parameters to hit exactly 200 clusters.
3. Build a small web dashboard to audition clusters and merge/split interactively.

---

*Project bootstrapped May 2025 â€“ innovation in progress ğŸš§*
